{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9111184d",
   "metadata": {},
   "source": [
    "# üîá Advanced Noise Cancellation & Safe Audio System\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates various noise cancellation techniques and implements a **Safe Audio Environment System** that keeps audio levels below **70 dB** for hearing protection.\n",
    "\n",
    "### üéØ Key Features:\n",
    "- **Real-time noise reduction** using spectral subtraction\n",
    "- **Adaptive volume control** to maintain safe dB levels\n",
    "- **Environmental noise learning** for personalized filtering\n",
    "- **Frequency analysis** and visualization\n",
    "- **Hearing protection** with automatic limiting\n",
    "\n",
    "### üìä Safety Standard:\n",
    "> **70 dB Threshold**: Sounds at or below 70 dB are generally considered safe for prolonged exposure without risk of hearing damage.\n",
    "\n",
    "Let's explore different approaches to noise cancellation and audio safety!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d72b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for advanced noise cancellation\n",
    "%pip install pyaudio numpy matplotlib scipy soundfile librosa pydub audioop-lts\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyaudio\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, ifft\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "print(\"‚úÖ All packages installed and imported successfully!\")\n",
    "print(\"üîß Setting up Safe Audio Environment System...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Audio Safety and dB Level Functions\n",
    "\n",
    "def calculate_db_level(audio_data):\n",
    "    \"\"\"Calculate dB level of audio data\"\"\"\n",
    "    if len(audio_data) == 0:\n",
    "        return -np.inf\n",
    "    \n",
    "    # Calculate RMS (Root Mean Square)\n",
    "    rms = np.sqrt(np.mean(audio_data ** 2))\n",
    "    \n",
    "    # Convert to dB relative to full scale\n",
    "    if rms > 0:\n",
    "        db_level = 20 * np.log10(rms)\n",
    "        # Rough calibration to approximate real-world dB levels\n",
    "        return db_level + 94  # Calibration offset\n",
    "    return -np.inf\n",
    "\n",
    "def is_safe_level(db_level, threshold=70.0):\n",
    "    \"\"\"Check if audio level is safe for prolonged exposure\"\"\"\n",
    "    return db_level <= threshold\n",
    "\n",
    "def apply_safety_limiting(audio_data, max_db=70.0):\n",
    "    \"\"\"Apply safety limiting to keep audio below specified dB level\"\"\"\n",
    "    current_db = calculate_db_level(audio_data)\n",
    "    \n",
    "    if current_db > max_db:\n",
    "        # Calculate reduction factor needed\n",
    "        reduction_db = current_db - max_db\n",
    "        reduction_factor = 10 ** (-reduction_db / 20.0)\n",
    "        \n",
    "        # Apply smooth reduction\n",
    "        audio_data = audio_data * reduction_factor\n",
    "        \n",
    "        # Apply soft limiting to prevent clipping\n",
    "        audio_data = np.tanh(audio_data * 0.8) * 0.8\n",
    "        \n",
    "    return audio_data, calculate_db_level(audio_data)\n",
    "\n",
    "# Test with sample data\n",
    "print(\"üß™ Testing safety functions...\")\n",
    "test_audio = np.random.normal(0, 0.3, 44100)  # 1 second of noise\n",
    "original_db = calculate_db_level(test_audio)\n",
    "safe_audio, safe_db = apply_safety_limiting(test_audio, max_db=70.0)\n",
    "\n",
    "print(f\"Original level: {original_db:.1f} dB\")\n",
    "print(f\"After safety limiting: {safe_db:.1f} dB\")\n",
    "print(f\"Safe for prolonged exposure: {is_safe_level(safe_db)}\")\n",
    "\n",
    "# Visualize the difference\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(test_audio[:1000])\n",
    "plt.title(f'Original Audio (Level: {original_db:.1f} dB)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(safe_audio[:1000])\n",
    "plt.title(f'Safety Limited Audio (Level: {safe_db:.1f} dB)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Sample')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b67d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sounddevice\n",
      "  Using cached sounddevice-0.5.2-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\dinesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dinesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Using cached sounddevice-0.5.2-py3-none-win_amd64.whl (363 kB)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Dinesh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sounddevice\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce85819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Dinesh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: soundfile in c:\\users\\dinesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dinesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dinesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from soundfile) (2.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dinesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Playing inverse sound...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%pip install soundfile\n",
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load your song\n",
    "filename = 'song.mp3'  # Replace with your WAV/FLAC/OGG file\n",
    "data, samplerate = sf.read(filename)\n",
    "# If stereo, convert to mono for demonstration (optional)\n",
    "if data.ndim > 1:\n",
    "    data = np.mean(data, axis=1)\n",
    "\n",
    "# Step 2: Invert the waveform\n",
    "inverse_data = 0 * data\n",
    "\n",
    "# Step 3: Play the inverted sound\n",
    "print(\"Playing inverse sound...\")\n",
    "sd.play(data, samplerate)\n",
    "sd.play(inverse_data, samplerate)\n",
    "sd.wait()\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa0293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Initializing Enhanced Audio Device Selector...\n",
      "Features:\n",
      "  üé§ PC Microphone input\n",
      "  üîä Headphone output\n",
      "  üìä Real-time visualization\n",
      "  üõ°Ô∏è 70 dB safety monitoring\n",
      "  üéöÔ∏è GUI device selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py:862: UserWarning: Glyph 127908 (\\N{MICROPHONE}) missing from font(s) DejaVu Sans.\n",
      "  func(*args)\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py:862: UserWarning: Glyph 128266 (\\N{SPEAKER WITH THREE SOUND WAVES}) missing from font(s) DejaVu Sans.\n",
      "  func(*args)\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py:862: UserWarning: Glyph 128200 (\\N{CHART WITH UPWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  func(*args)\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py:862: UserWarning: Glyph 128737 (\\N{SHIELD}) missing from font(s) DejaVu Sans.\n",
      "  func(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Input: Microphone Array (AMD Audio Dev\n",
      "üîä Output: Primary Sound Driver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_40076\\3671690607.py:220: UserWarning: frames=None which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
      "  self.animation = animation.FuncAnimation(self.fig, self.update_plots,\n",
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_40076\\3671690607.py:222: UserWarning: Glyph 127908 (\\N{MICROPHONE}) missing from font(s) DejaVu Sans.\n",
      "  self.canvas.draw()\n",
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_40076\\3671690607.py:222: UserWarning: Glyph 128266 (\\N{SPEAKER WITH THREE SOUND WAVES}) missing from font(s) DejaVu Sans.\n",
      "  self.canvas.draw()\n",
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_40076\\3671690607.py:222: UserWarning: Glyph 128200 (\\N{CHART WITH UPWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  self.canvas.draw()\n",
      "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_40076\\3671690607.py:222: UserWarning: Glyph 128737 (\\N{SHIELD}) missing from font(s) DejaVu Sans.\n",
      "  self.canvas.draw()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ Audio streams started successfully!\n",
      "‚èπÔ∏è Audio processing stopped\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# üéß Enhanced Audio Device Selection with GUI Controls\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.widgets import Button\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "class AudioDeviceSelector:\n",
    "    def __init__(self):\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        self.selected_input_device = None\n",
    "        self.selected_output_device = None\n",
    "        self.audio_processor = None\n",
    "        \n",
    "    def get_audio_devices(self):\n",
    "        \"\"\"Get all available audio input and output devices\"\"\"\n",
    "        input_devices = []\n",
    "        output_devices = []\n",
    "        \n",
    "        for i in range(self.audio.get_device_count()):\n",
    "            try:\n",
    "                device_info = self.audio.get_device_info_by_index(i)\n",
    "                \n",
    "                # Input devices (microphones)\n",
    "                if device_info['maxInputChannels'] > 0:\n",
    "                    device_type = \"üé§ MICROPHONE\"\n",
    "                    if any(keyword in device_info['name'].lower() for keyword in \n",
    "                          ['desktop', 'realtek', 'amd audio', 'pc', 'array']):\n",
    "                        device_type = \"üñ•Ô∏è DESKTOP MICROPHONE\"\n",
    "                    elif any(keyword in device_info['name'].lower() for keyword in \n",
    "                           ['headset', 'headphone', 'bluetooth']):\n",
    "                        device_type = \"üéß HEADPHONE/HEADSET MIC\"\n",
    "                        \n",
    "                    input_devices.append({\n",
    "                        'index': i,\n",
    "                        'name': device_info['name'],\n",
    "                        'type': device_type,\n",
    "                        'channels': device_info['maxInputChannels'],\n",
    "                        'rate': device_info['defaultSampleRate']\n",
    "                    })\n",
    "                \n",
    "                # Output devices (speakers/headphones)\n",
    "                if device_info['maxOutputChannels'] > 0:\n",
    "                    device_type = \"üîä SPEAKER\"\n",
    "                    if any(keyword in device_info['name'].lower() for keyword in \n",
    "                          ['headset', 'headphone', 'bluetooth']):\n",
    "                        device_type = \"üéß HEADPHONES\"\n",
    "                    elif any(keyword in device_info['name'].lower() for keyword in \n",
    "                           ['speaker', 'realtek', 'amd audio']):\n",
    "                        device_type = \"üñ•Ô∏è PC SPEAKERS\"\n",
    "                        \n",
    "                    output_devices.append({\n",
    "                        'index': i,\n",
    "                        'name': device_info['name'],\n",
    "                        'type': device_type,\n",
    "                        'channels': device_info['maxOutputChannels'],\n",
    "                        'rate': device_info['defaultSampleRate']\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "        return input_devices, output_devices\n",
    "    \n",
    "    def create_device_selection_gui(self):\n",
    "        \"\"\"Create GUI for device selection with integrated audio visualization\"\"\"\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"üéß Audio Device & Real-time Visualizer\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "        # Get devices\n",
    "        input_devices, output_devices = self.get_audio_devices()\n",
    "        \n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Device selection frame\n",
    "        device_frame = ttk.LabelFrame(main_frame, text=\"üé§üîä Audio Device Selection\", padding=10)\n",
    "        device_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        # Input device selection\n",
    "        ttk.Label(device_frame, text=\"üé§ Select Microphone:\", font=(\"Arial\", 11, \"bold\")).grid(row=0, column=0, sticky=\"w\", pady=5)\n",
    "        self.input_var = tk.StringVar()\n",
    "        input_combo = ttk.Combobox(device_frame, textvariable=self.input_var, width=60, state=\"readonly\")\n",
    "        input_combo.grid(row=0, column=1, padx=(10, 0), pady=5, sticky=\"ew\")\n",
    "        \n",
    "        input_options = []\n",
    "        for device in input_devices:\n",
    "            option = f\"[{device['index']}] {device['name']} - {device['type']}\"\n",
    "            input_options.append(option)\n",
    "        input_combo['values'] = input_options\n",
    "        \n",
    "        # Pre-select PC microphone if available\n",
    "        for i, device in enumerate(input_devices):\n",
    "            if \"üñ•Ô∏è DESKTOP MICROPHONE\" in device['type']:\n",
    "                input_combo.current(i)\n",
    "                break\n",
    "        \n",
    "        # Output device selection\n",
    "        ttk.Label(device_frame, text=\"üîä Select Output:\", font=(\"Arial\", 11, \"bold\")).grid(row=1, column=0, sticky=\"w\", pady=5)\n",
    "        self.output_var = tk.StringVar()\n",
    "        output_combo = ttk.Combobox(device_frame, textvariable=self.output_var, width=60, state=\"readonly\")\n",
    "        output_combo.grid(row=1, column=1, padx=(10, 0), pady=5, sticky=\"ew\")\n",
    "        \n",
    "        output_options = []\n",
    "        for device in output_devices:\n",
    "            option = f\"[{device['index']}] {device['name']} - {device['type']}\"\n",
    "            output_options.append(option)\n",
    "        output_combo['values'] = output_options\n",
    "        \n",
    "        # Pre-select headphones if available\n",
    "        for i, device in enumerate(output_devices):\n",
    "            if \"üéß HEADPHONES\" in device['type']:\n",
    "                output_combo.current(i)\n",
    "                break\n",
    "        \n",
    "        device_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # Control buttons\n",
    "        button_frame = ttk.Frame(device_frame)\n",
    "        button_frame.grid(row=2, column=0, columnspan=2, pady=10)\n",
    "        \n",
    "        start_btn = ttk.Button(button_frame, text=\"üéµ Start Audio Processing\", \n",
    "                              command=lambda: self.start_audio_processing(input_devices, output_devices))\n",
    "        start_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        stop_btn = ttk.Button(button_frame, text=\"‚èπÔ∏è Stop\", command=self.stop_audio_processing)\n",
    "        stop_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Matplotlib figure frame\n",
    "        plot_frame = ttk.LabelFrame(main_frame, text=\"üìä Real-time Audio Visualization\", padding=5)\n",
    "        plot_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create matplotlib figure\n",
    "        self.fig, ((self.ax1, self.ax2), (self.ax3, self.ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        self.fig.suptitle('Real-time Audio Processing & Visualization', fontsize=14)\n",
    "        \n",
    "        # Configure subplots\n",
    "        self.ax1.set_title('üé§ Input Waveform')\n",
    "        self.ax1.set_ylim(-1, 1)\n",
    "        self.ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        self.ax2.set_title('üîä Output Waveform')\n",
    "        self.ax2.set_ylim(-1, 1)\n",
    "        self.ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        self.ax3.set_title('üìà Frequency Spectrum')\n",
    "        self.ax3.set_xlabel('Frequency (Hz)')\n",
    "        self.ax3.set_ylabel('Magnitude')\n",
    "        self.ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        self.ax4.set_title('üõ°Ô∏è Safety Monitor')\n",
    "        self.ax4.set_xlabel('Time')\n",
    "        self.ax4.set_ylabel('dB Level')\n",
    "        self.ax4.axhline(y=70, color='red', linestyle='--', label='70 dB Safety Limit')\n",
    "        self.ax4.legend()\n",
    "        self.ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Embed matplotlib in tkinter\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, plot_frame)\n",
    "        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Initialize plot lines\n",
    "        self.line_input, = self.ax1.plot([], [], 'b-', linewidth=1)\n",
    "        self.line_output, = self.ax2.plot([], [], 'g-', linewidth=1)\n",
    "        self.line_freq, = self.ax3.plot([], [], 'r-', linewidth=1)\n",
    "        self.line_db, = self.ax4.plot([], [], 'orange', linewidth=2)\n",
    "        \n",
    "        # Audio processing variables\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.db_history = []\n",
    "        self.time_history = []\n",
    "        self.processing = False\n",
    "        \n",
    "        # Status\n",
    "        self.status_label = ttk.Label(main_frame, text=\"üî¥ Ready - Select devices and click Start\", \n",
    "                                     font=(\"Arial\", 10))\n",
    "        self.status_label.pack(pady=5)\n",
    "        \n",
    "        return self.root, input_devices, output_devices\n",
    "    \n",
    "    def start_audio_processing(self, input_devices, output_devices):\n",
    "        \"\"\"Start real-time audio processing with selected devices\"\"\"\n",
    "        # Get selected devices\n",
    "        input_selection = self.input_var.get()\n",
    "        output_selection = self.output_var.get()\n",
    "        \n",
    "        if not input_selection or not output_selection:\n",
    "            messagebox.showerror(\"Error\", \"Please select both input and output devices!\")\n",
    "            return\n",
    "        \n",
    "        # Extract device indices\n",
    "        input_index = int(input_selection.split(']')[0].split('[')[1])\n",
    "        output_index = int(output_selection.split(']')[0].split('[')[1])\n",
    "        \n",
    "        # Find selected device info\n",
    "        selected_input = next(d for d in input_devices if d['index'] == input_index)\n",
    "        selected_output = next(d for d in output_devices if d['index'] == output_index)\n",
    "        \n",
    "        self.selected_input_device = selected_input\n",
    "        self.selected_output_device = selected_output\n",
    "        \n",
    "        print(f\"üé§ Input: {selected_input['name']}\")\n",
    "        print(f\"üîä Output: {selected_output['name']}\")\n",
    "        \n",
    "        # Start audio processing thread\n",
    "        self.processing = True\n",
    "        self.audio_thread = threading.Thread(target=self.audio_processing_loop)\n",
    "        self.audio_thread.daemon = True\n",
    "        self.audio_thread.start()\n",
    "        \n",
    "        # Start visualization\n",
    "        self.animation = animation.FuncAnimation(self.fig, self.update_plots, \n",
    "                                               interval=50, blit=False)\n",
    "        self.canvas.draw()\n",
    "        \n",
    "        self.status_label.config(text=\"üü¢ Processing - Audio active with safety monitoring\")\n",
    "    \n",
    "    def audio_processing_loop(self):\n",
    "        \"\"\"Main audio processing loop with safety features\"\"\"\n",
    "        CHUNK = 1024\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        \n",
    "        try:\n",
    "            # Input stream (microphone)\n",
    "            input_stream = self.audio.open(\n",
    "                format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                input_device_index=self.selected_input_device['index'],\n",
    "                frames_per_buffer=CHUNK\n",
    "            )\n",
    "            \n",
    "            # Output stream (headphones/speakers)\n",
    "            output_stream = self.audio.open(\n",
    "                format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                output=True,\n",
    "                output_device_index=self.selected_output_device['index'],\n",
    "                frames_per_buffer=CHUNK\n",
    "            )\n",
    "            \n",
    "            print(\"üéµ Audio streams started successfully!\")\n",
    "            \n",
    "            while self.processing:\n",
    "                # Read from microphone\n",
    "                input_data = input_stream.read(CHUNK, exception_on_overflow=False)\n",
    "                audio_input = np.frombuffer(input_data, dtype=np.int16) / 32768.0\n",
    "                \n",
    "                # Apply safety processing\n",
    "                processed_audio = self.apply_safety_processing(audio_input)\n",
    "                \n",
    "                # Convert back to output format\n",
    "                output_data = (processed_audio * 32767).astype(np.int16).tobytes()\n",
    "                \n",
    "                # Send to output device\n",
    "                output_stream.write(output_data)\n",
    "                \n",
    "                # Queue data for visualization\n",
    "                if not self.audio_queue.full():\n",
    "                    self.audio_queue.put({\n",
    "                        'input': audio_input,\n",
    "                        'output': processed_audio,\n",
    "                        'timestamp': len(self.time_history)\n",
    "                    })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Audio processing error: {e}\")\n",
    "            messagebox.showerror(\"Audio Error\", f\"Failed to start audio processing:\\n{e}\")\n",
    "        finally:\n",
    "            try:\n",
    "                input_stream.stop_stream()\n",
    "                input_stream.close()\n",
    "                output_stream.stop_stream()\n",
    "                output_stream.close()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def apply_safety_processing(self, audio_data):\n",
    "        \"\"\"Apply safety processing to keep audio below 70 dB\"\"\"\n",
    "        # Calculate current dB level\n",
    "        rms = np.sqrt(np.mean(audio_data ** 2))\n",
    "        if rms > 0:\n",
    "            db_level = 20 * np.log10(rms) + 94  # Calibration offset\n",
    "        else:\n",
    "            db_level = -np.inf\n",
    "        \n",
    "        # Apply safety limiting\n",
    "        max_db = 70.0\n",
    "        if db_level > max_db:\n",
    "            reduction_db = db_level - max_db\n",
    "            reduction_factor = 10 ** (-reduction_db / 20.0)\n",
    "            processed_audio = audio_data * reduction_factor\n",
    "        else:\n",
    "            processed_audio = audio_data.copy()\n",
    "        \n",
    "        # Store for monitoring\n",
    "        self.db_history.append(db_level if db_level > -np.inf else 0)\n",
    "        self.time_history.append(len(self.time_history))\n",
    "        \n",
    "        # Keep only recent history\n",
    "        if len(self.db_history) > 500:\n",
    "            self.db_history.pop(0)\n",
    "            self.time_history.pop(0)\n",
    "        \n",
    "        return processed_audio\n",
    "    \n",
    "    def update_plots(self, frame):\n",
    "        \"\"\"Update visualization plots\"\"\"\n",
    "        if not self.audio_queue.empty():\n",
    "            try:\n",
    "                data = self.audio_queue.get_nowait()\n",
    "                \n",
    "                # Update waveforms\n",
    "                x_axis = np.arange(len(data['input']))\n",
    "                \n",
    "                self.line_input.set_data(x_axis, data['input'])\n",
    "                self.ax1.set_xlim(0, len(data['input']))\n",
    "                self.ax1.set_ylim(-1, 1)\n",
    "                \n",
    "                self.line_output.set_data(x_axis, data['output'])\n",
    "                self.ax2.set_xlim(0, len(data['output']))\n",
    "                self.ax2.set_ylim(-1, 1)\n",
    "                \n",
    "                # Update frequency spectrum\n",
    "                windowed = data['input'] * np.hanning(len(data['input']))\n",
    "                fft_data = np.fft.fft(windowed)\n",
    "                magnitude = np.abs(fft_data[:len(fft_data)//2])\n",
    "                freqs = np.fft.fftfreq(len(fft_data), 1/44100)[:len(fft_data)//2]\n",
    "                \n",
    "                self.line_freq.set_data(freqs, magnitude)\n",
    "                self.ax3.set_xlim(0, 8000)  # Show up to 8kHz\n",
    "                if magnitude.max() > 0:\n",
    "                    self.ax3.set_ylim(0, magnitude.max() * 1.1)\n",
    "                \n",
    "            except queue.Empty:\n",
    "                pass\n",
    "        \n",
    "        # Update dB monitoring\n",
    "        if self.db_history:\n",
    "            self.line_db.set_data(self.time_history, self.db_history)\n",
    "            self.ax4.set_xlim(max(0, len(self.time_history) - 200), len(self.time_history))\n",
    "            self.ax4.set_ylim(0, max(80, max(self.db_history[-50:]) + 10))\n",
    "        \n",
    "        return self.line_input, self.line_output, self.line_freq, self.line_db\n",
    "    \n",
    "    def stop_audio_processing(self):\n",
    "        \"\"\"Stop audio processing\"\"\"\n",
    "        self.processing = False\n",
    "        if hasattr(self, 'animation'):\n",
    "            self.animation.event_source.stop()\n",
    "        self.status_label.config(text=\"üî¥ Stopped\")\n",
    "        print(\"‚èπÔ∏è Audio processing stopped\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the application\"\"\"\n",
    "        root, input_devices, output_devices = self.create_device_selection_gui()\n",
    "        \n",
    "        def on_closing():\n",
    "            self.stop_audio_processing()\n",
    "            self.audio.terminate()\n",
    "            root.destroy()\n",
    "        \n",
    "        root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "        root.mainloop()\n",
    "\n",
    "# Create and run the audio device selector\n",
    "print(\"üéß Initializing Enhanced Audio Device Selector...\")\n",
    "print(\"Features:\")\n",
    "print(\"  üé§ PC Microphone input\")\n",
    "print(\"  üîä Headphone output\") \n",
    "print(\"  üìä Real-time visualization\")\n",
    "print(\"  üõ°Ô∏è 70 dB safety monitoring\")\n",
    "print(\"  üéöÔ∏è GUI device selection\")\n",
    "\n",
    "selector = AudioDeviceSelector()\n",
    "selector.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
